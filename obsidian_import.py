#!/usr/bin/env python3

# ğŸ“ Obsidian å¯¼å…¥éœ€æ±‚:
# (Copilot å¿…é¡»åœ¨ç¼–è¾‘ä»£ç æ—¶åŒæ­¥è¿™äº›éœ€æ±‚ï¼Œå¦‚æœéœ€æ±‚å‘ç”Ÿå˜åŒ–ï¼)
#
# æ­¤è„šæœ¬å¤„ç†ä» Notion å¯¼å‡ºçš„ç›®å½•ï¼Œå…¶ä¸­åŒ…å«å¤šä¸ª Markdown æ–‡ä»¶
# ï¼ˆæ–‡ä»¶åæ ¼å¼ä¸ºï¼š"DocumentName UID.md"ï¼‰ã€‚å¦‚æœ Markdown æ–‡ä»¶å¼•ç”¨äº†é™„ä»¶ï¼Œ
# å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªå•ç‹¬çš„ç›®å½•ä¸­ï¼ˆç›®å½•åç§°ä¸ Markdown æ–‡ä»¶ç›¸åŒï¼‰ã€‚å¯èƒ½æœ‰å¤šä¸ªé™„ä»¶ã€‚
# å¦‚æœæ–‡æ¡£åç§°ç›¸åŒï¼Œåˆ™ä½¿ç”¨ UID æ¥åŒºåˆ†å®ƒä»¬ã€‚
#
# ğŸ¯ ç›®æ ‡:
# - ğŸ“„ ä» Markdown æ–‡ä»¶åä¸­ç§»é™¤ UIDï¼ˆå¦‚æœæ²¡æœ‰é‡å¤æ–‡ä»¶ï¼‰ã€‚
# - ğŸ—‚ï¸ å°†æ‰€æœ‰é™„ä»¶æ•´åˆåˆ°ä¸€ä¸ª "Resource" ç›®å½•ä¸­ã€‚
# - âœï¸ æ ¹æ® Markdown æ–‡ä»¶åé‡å‘½åé™„ä»¶ã€‚å¦‚æœæœ‰å¤šä¸ªé™„ä»¶ï¼Œ
#   åœ¨åç§°åé™„åŠ åºåˆ—å·ã€‚
# - ğŸ–¼ï¸ å¦‚æœ Markdown æ–‡ä»¶ä»…å¼•ç”¨ä¸€ä¸ªå›¾ç‰‡ï¼Œåˆ™ä¿æŒå›¾ç‰‡åç§°ä¸æ–‡æ¡£åç§°ç›¸åŒï¼Œ
#   ä¸æ·»åŠ åºåˆ—å·ã€‚
# - ğŸ”„ æ›´æ–° Markdown æ–‡ä»¶ä¸­çš„å¼•ç”¨ä»¥åæ˜ æ–°çš„é™„ä»¶è·¯å¾„ã€‚
# - ğŸ·ï¸ æ ¹æ®ç”¨æˆ·å®šä¹‰çš„è§„åˆ™å¤„ç†å¹¶è½¬æ¢ Markdown æ–‡ä»¶ä¸­çš„å…ƒæ•°æ®ã€‚
#   - âœ… æ ¹æ®é…ç½®æ–‡ä»¶ä¸­å®šä¹‰çš„è§„åˆ™éªŒè¯å…ƒæ•°æ®ã€‚
#   - ğŸ› ï¸ ä¿®æ”¹å…ƒæ•°æ®é”®æˆ–å€¼ï¼Œè¿½åŠ é¢å¤–å†…å®¹ï¼Œæˆ–åˆ é™¤å…ƒæ•°æ®æ¡ç›®ã€‚
#   - ğŸ“‹ è®°å½•æœªæ˜ å°„çš„å…ƒæ•°æ®ä»¥ä¾›å®¡æŸ¥ã€‚
# - ğŸ§¹ æ¸…ç†å·²å¤„ç†çš„ Markdown æ–‡ä»¶åŠå…¶å¯¹åº”çš„é™„ä»¶ç›®å½•ã€‚
#
# ğŸ“‹ æ­¥éª¤:
# 1) ğŸ·ï¸ å¤„ç† Markdown æ–‡ä»¶ä¸­çš„å…ƒæ•°æ®ï¼š
#    - âœ… æ ¹æ®ç”¨æˆ·å®šä¹‰çš„è§„åˆ™éªŒè¯å…ƒæ•°æ®ã€‚
#    - ğŸ› ï¸ æ ¹æ®è§„åˆ™è½¬æ¢å…ƒæ•°æ®é”®æˆ–å€¼ã€‚
#    - ğŸ“‹ åœ¨ `unmapped_metadata` å­—å…¸ä¸­è®°å½•æœªæ˜ å°„çš„å…ƒæ•°æ®ä»¥ä¾›å®¡æŸ¥ã€‚
# 2) ğŸ” æœç´¢ Markdown æ–‡ä»¶ä¸­å¼•ç”¨çš„é™„ä»¶å¹¶å°†å…¶ç§»åŠ¨åˆ° "Resource" ç›®å½•ï¼š
#    - ğŸ–¼ï¸ å¦‚æœåªæœ‰ä¸€ä¸ªé™„ä»¶ï¼Œå°†å…¶é‡å‘½åä¸ºä¸ Markdown æ–‡ä»¶åç›¸åŒä¸”ä¸å¸¦åºåˆ—å·ã€‚
#    - ğŸ“š å¦‚æœæœ‰å¤šä¸ªé™„ä»¶ï¼Œåœ¨åç§°åé™„åŠ åºåˆ—å·ã€‚
#    - ğŸ”„ ç»´æŠ¤æ—§é™„ä»¶è·¯å¾„åˆ°æ–°è·¯å¾„çš„æ˜ å°„ (`path_mapping`) ä»¥æ›´æ–°å¼•ç”¨ã€‚
#    - ğŸ—‘ï¸ å¦‚æœé™„ä»¶ç›®å½•ä¸­çš„æ–‡ä»¶æ•°é‡ä¸ Markdown æ–‡ä»¶ä¸­çš„å¼•ç”¨æ•°é‡ä¸€è‡´ï¼Œ
#      åˆ›å»ºæ¸…ç†è¯¥é™„ä»¶ç›®å½•çš„ä»»åŠ¡ã€‚
# 3) ğŸ”„ æ›´æ–° Markdown æ–‡ä»¶ä»¥åæ˜ æ–°çš„é™„ä»¶è·¯å¾„ï¼š
#    - ğŸ“„ ä½¿ç”¨ `path_mapping` æ›¿æ¢ Markdown å†…å®¹ä¸­çš„æ—§è·¯å¾„ä¸ºæ–°è·¯å¾„ã€‚
#    - åŒ…æ‹¬è¡Œå·ã€åŸå§‹æ–‡æœ¬å’Œæ›´æ–°åçš„æ–‡æœ¬ä»¥æ›´æ–°é“¾æ¥ã€‚
# 4) âœï¸ é‡å‘½å Markdown æ–‡ä»¶ä»¥ç§»é™¤ UIDï¼ˆå¦‚æœæ²¡æœ‰é‡å¤æ–‡ä»¶ï¼‰ï¼š
#    - ğŸ“„ åœ¨å•ç‹¬çš„è¡Œä¸­æ˜¾ç¤ºæºè·¯å¾„å’Œç›®æ ‡è·¯å¾„ä»¥ä¾¿äºæ¯”è¾ƒã€‚
# 5) ğŸ§¹ æ¸…ç†å·²å¤„ç†çš„ Markdown æ–‡ä»¶åŠå…¶å¯¹åº”çš„é™„ä»¶ç›®å½•ï¼š
#    - ğŸ—‘ï¸ åœ¨å¤„ç†ååˆ é™¤åŸå§‹ Markdown æ–‡ä»¶åŠå…¶é™„ä»¶ç›®å½•ã€‚
# 6) ğŸ“Š æ‰«æåæ‰“å°æ€»ç»“ä»»åŠ¡çš„ç»Ÿè®¡ä¿¡æ¯ã€‚
# 7) â“ åœ¨æ‰§è¡Œä»»åŠ¡åˆ—è¡¨ä¹‹å‰æç¤ºç”¨æˆ·ç¡®è®¤ã€‚
# 8) ğŸ”„ å¦‚æœåœ¨æ‰«ææœŸé—´æ£€æµ‹åˆ°é‡å¤åç§°ï¼Œé™„åŠ åºåˆ—å·ä»¥è§£å†³å†²çªã€‚
#    ç¡®ä¿ Markdown æ–‡ä»¶ä¸å…¶é™„ä»¶ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚
# 9) ğŸ“ åœ¨æ‰§è¡Œä»»åŠ¡åç”Ÿæˆæ€»ç»“æŠ¥å‘Šã€‚

# ğŸ·ï¸ å…³äºå…ƒæ•°æ®çš„è¯´æ˜:
# å…ƒæ•°æ®æ˜¯ Markdown æ–‡ä»¶ä¸­çš„å­—å…¸æ•°æ®ï¼Œæ ¼å¼ä¸º "meta name: meta value"ã€‚
# æ¯ä¸ªå…ƒæ•°æ®å ä¸€è¡Œï¼Œé€šå¸¸å‡ºç°åœ¨æ–‡ä»¶çš„å‰åè¡Œå†…ã€‚
# å¤šä¸ªå…ƒæ•°æ®æ¡ç›®ä¹‹é—´æ²¡æœ‰ç©ºè¡Œã€‚
# å…ƒæ•°æ®éƒ¨åˆ†é€šå¸¸é€šè¿‡ç©ºè¡Œæˆ– "---" è¡Œä¸å†…å®¹çš„å…¶ä½™éƒ¨åˆ†åˆ†éš”ã€‚

# å…ƒæ•°æ®å¤„ç†ç±»å‹å’Œæ“ä½œ:
# 1) "retain" - ä¿ç•™å…ƒæ•°æ®ï¼Œä¸åšä»»ä½•æ›´æ”¹ã€‚
#    - å¦‚æœ "retain" æ˜¯å”¯ä¸€çš„æ“ä½œï¼Œåˆ™å…ƒæ•°æ®å°†è¢«è·³è¿‡ï¼Œä¸åšä»»ä½•æ›´æ”¹ã€‚
#    - å¦‚æœåŒæ—¶å­˜åœ¨ "retain" å’Œ "delete"ï¼Œ"delete" ä¼˜å…ˆï¼Œå…ƒæ•°æ®å°†è¢«åˆ é™¤ã€‚
# 2) "delete" - å®Œå…¨åˆ é™¤å…ƒæ•°æ®æ¡ç›®ã€‚
#    - æ­¤æ“ä½œä¼˜å…ˆçº§æœ€é«˜ï¼Œå¦‚æœå­˜åœ¨ï¼Œå°†è¦†ç›–å…¶ä»–æ“ä½œã€‚
# 3) "rename" - æ›´æ”¹å…ƒæ•°æ®é”®åï¼ŒåŒæ—¶ä¿ç•™å€¼ã€‚
# 4) "modify_value" - ä½¿ç”¨ç›´æ¥æ˜ å°„æˆ–æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼è½¬æ¢å…ƒæ•°æ®å€¼ã€‚
#    - ç›´æ¥æ˜ å°„ï¼šç”¨é¢„å®šä¹‰çš„æ˜ å°„æ›¿æ¢ç‰¹å®šå€¼ã€‚
#    - æ­£åˆ™æ˜ å°„ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¹¶æ›¿æ¢å€¼ã€‚
#    - "modify_value" åœ¨ "append_after" å’Œ "rename" ä¹‹å‰åº”ç”¨ã€‚
# 5) "append_after" - åœ¨ç°æœ‰å…ƒæ•°æ®å€¼åæ·»åŠ æ–‡æœ¬ã€‚
#
# æœªæ˜ å°„çš„å…ƒæ•°æ®:
# - ä¸ç¬¦åˆé…ç½®ä¸­ä»»ä½•è§„åˆ™çš„å…ƒæ•°æ®å€¼å°†è¢«è®°å½•ä»¥ä¾›å®¡æŸ¥ã€‚
# - è¿™äº›æœªæ˜ å°„çš„å€¼å­˜å‚¨åœ¨å­—å…¸ (`unmapped_metadata`) ä¸­ä»¥ä¾›è¿›ä¸€æ­¥åˆ†æã€‚

import os
import re
import shutil
import argparse
import sys  # Add this import for sys.argv
from collections import defaultdict
from enum import Enum
from pathlib import Path
import time
from urllib.parse import quote, unquote
import yaml
import datetime  # Added for timestamping log entries
import shutil  # For getting terminal size

class TaskType(Enum):
    """Enum defining different types of tasks that can be performed during the import process."""
    RENAME_MD = "RENAME_MD"
    MOVE_ATTACHMENT = "MOVE_ATTACHMENT"
    UPDATE_ATTACH_REF = "UPDATE_ATTACH_REF"
    TRANSFORM_METADATA = "TRANSFORM_METADATA"
    MAP_METADATA = "MAP_METADATA"
    CLEANUP = "CLEANUP"

#############################################################
# CONFIGURATION AND LOGGING FUNCTIONS
#############################################################

# Functions in this section handle configuration loading and logging.
# These include `load_config`, `trace_debug`, and `log_debug`.

def load_config(config_path):
    """
    ä» YAML æ–‡ä»¶åŠ è½½é…ç½®ã€‚

    å‚æ•°:
        config_path (str): é…ç½®æ–‡ä»¶çš„è·¯å¾„

    è¿”å›:
        dict: é…ç½®å­—å…¸ï¼Œå¦‚æœåŠ è½½å¤±è´¥åˆ™è¿”å›ç©ºå­—å…¸
    """
    try:
        with open(config_path, "r") as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"Error loading configuration file {config_path}: {e}")
        return {}

def trace_debug(message, config):
    """
    å¦‚æœå¯ç”¨äº† --debugï¼Œåˆ™æ‰“å°è°ƒè¯•ä¿¡æ¯ã€‚

    å‚æ•°:
        message (str): è¦è®°å½•çš„è°ƒè¯•ä¿¡æ¯
        config (dict): é…ç½®å­—å…¸
    """
    if config.get("debug", False):  # ä½¿ç”¨ --debug å‚æ•°æ§åˆ¶è°ƒè¯•è¾“å‡º
        print(f"ğŸ è°ƒè¯•: {message}")
        log_debug(f"ğŸ è°ƒè¯•: {message}", config)

def log_debug(message, config):
    """
    å¦‚æœé…ç½®ä¸­å¯ç”¨äº† log_debugï¼Œåˆ™å°†æ“ä½œè®°å½•åˆ°æ–‡ä»¶ã€‚

    å‚æ•°:
        message (str): è¦è®°å½•çš„æ“ä½œä¿¡æ¯
        config (dict): åŒ…å«æ—¥å¿—è®¾ç½®çš„é…ç½®å­—å…¸
    """
    if config and config.get("log_debug", False):
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_file = Path(config.get("log_file", "obsidian_import.log"))
        with open(log_file, "a") as f:
            f.write(f"[{timestamp}] æ—¥å¿—: {message}\n")

#############################################################
# METADATA VALIDATION AND TASK GENERATION
#############################################################

# Functions in this section handle metadata validation and task generation.
# These include `validate_metadata_mappings`, `read_metadata_lines`,
# `process_metadata_line`, `apply_metadata_actions`, and `generate_metadata_tasks`.

def validate_metadata_mappings(lines, metadata_rules, unmapped_metadata):
    """
    æ ¹æ®è§„åˆ™éªŒè¯å…ƒæ•°æ®å€¼å¹¶è·Ÿè¸ªæœªæ˜ å°„çš„å…ƒæ•°æ®ã€‚

    å‚æ•°:
        lines (list): Markdown æ–‡ä»¶ä¸­çš„è¡Œåˆ—è¡¨
        metadata_rules (dict): å¤„ç†å…ƒæ•°æ®çš„è§„åˆ™
        unmapped_metadata (dict): ç”¨äºæ”¶é›†æœªæ˜ å°„å…ƒæ•°æ®å€¼çš„å­—å…¸
    """
    for line in lines:
        key, sep, value = line.partition(": ")
        if not sep:  # Skip lines that are not metadata
            continue

        rule = metadata_rules.get(key)
        if not rule:  # No rule, skip validation
            continue

        actions = rule.get("actions", [])
        for action in actions:
            if action.get("type") == "modify_value":
                value_mapping = action.get("value_mapping", {})
                if value.strip() not in value_mapping and value.strip() not in unmapped_metadata.get(key, set()):
                    unmapped_metadata.setdefault(key, set()).add(value.strip())
    trace_debug(f"éªŒè¯å…ƒæ•°æ®æ˜ å°„å®Œæˆ: {unmapped_metadata}", None)

def print_progress(step, total_steps):
    """
    æ‰“å°å½“å‰æ­¥éª¤çš„è¿›åº¦ã€‚

    å‚æ•°:
        step (int): å½“å‰æ­¥éª¤ç¼–å·
        total_steps (int): æ€»æ­¥éª¤æ•°
    """
    print(f"ç¬¬ {step}/{total_steps} æ­¥å·²å®Œæˆã€‚")

def read_metadata_lines(md_file, metadata_rules, config):
    """
    ä» Markdown æ–‡ä»¶ä¸­æå–å…ƒæ•°æ®è¡Œï¼ˆåŸºäºæ–°è§„åˆ™ï¼‰ã€‚

    å‚æ•°:
        md_file (str æˆ– Path): Markdown æ–‡ä»¶çš„è·¯å¾„
        metadata_rules (dict): å¤„ç†å…ƒæ•°æ®çš„è§„åˆ™
        config (dict): é…ç½®å­—å…¸ï¼Œç”¨äºæ—¥å¿—è®°å½•

    è¿”å›:
        list: å…ƒæ•°æ®è¡Œçš„åˆ—è¡¨
    """
    try:
        with open(md_file, "r") as f:
            content = f.readlines()

        trace_debug(f"Reading metadata lines from {md_file}", config)

        # Step 1: Read the first 10 lines
        first_10_lines = content[:10]

        # Step 2: Check for a match in metadata_rules
        metadata_start = -1
        for i, line in enumerate(first_10_lines):
            key, sep, value = line.partition(": ")
            if sep and key.strip() in metadata_rules:
                metadata_start = i
                break

        if metadata_start == -1:
            trace_debug(f"No metadata match found in the first 10 lines of {md_file}", config)
            return []

        # Step 3: Expand the metadata region
        metadata_lines = []
        # Search backward
        for i in range(metadata_start, -1, -1):
            line = content[i].strip()
            if not line or line == "---":  # Stop at empty or "---" lines
                break
            if ": " in line:  # Include lines with "key: value" format
                metadata_lines.insert(0, line)

        # Search forward
        for i in range(metadata_start + 1, len(content)):
            line = content[i].strip()
            if not line or line == "---":  # Stop at empty or "---" lines
                break
            if ": " in line:  # Include lines with "key: value" format
                metadata_lines.append(line)

        trace_debug(f"ä» {md_file} æå–çš„å…ƒæ•°æ®è¡Œ: {metadata_lines}", config)
        return metadata_lines
    except Exception as e:
        trace_debug(f"Error reading metadata from {md_file}: {e}", config)
        return []

def process_metadata_line(line, metadata_rules, config):
    """
    å¤„ç†å•è¡Œå…ƒæ•°æ®å¹¶æ ¹æ®è§„åˆ™ç”Ÿæˆä»»åŠ¡ã€‚

    å‚æ•°:
        line (str): å•è¡Œå…ƒæ•°æ®
        metadata_rules (dict): å¤„ç†å…ƒæ•°æ®çš„è§„åˆ™

    è¿”å›:
        list: è½¬æ¢å…ƒæ•°æ®çš„ä»»åŠ¡åˆ—è¡¨
    """
    key, sep, value = line.partition(": ")
    if not sep:
        return []

    trace_debug(f"å¼€å§‹å¤„ç†å…ƒæ•°æ®è¡Œâ€¦â€¦: {line}", config)

    value = value.strip()
    matching_keys = [rule_key for rule_key in metadata_rules if key.startswith(rule_key)]
    if not matching_keys:
        trace_debug(f"âš ï¸ Warning: No rule defined for metadata key '{key}'.", config)
        return []

    rule = metadata_rules[matching_keys[0]]
    actions = rule.get("actions", [])

    if any(action.get("type") == "delete" for action in actions):
        task = {"type": TaskType.TRANSFORM_METADATA.value, "key": key, "action": {"type": "delete"}}
        trace_debug(f"â• Added metadata task: {task}", config)
        return [task]

    if any(action.get("type") == "retain" for action in actions) and len(actions) == 1:
        return []

    tasks = apply_metadata_actions(key, value, actions)
    
    # Log each metadata task that was generated
    for task in tasks:
        trace_debug(f"â• Added metadata task: {task}", config)
        
    return tasks

def apply_metadata_actions(key, value, actions):
    """
    å¯¹é”®å€¼å¯¹åº”ç”¨å…ƒæ•°æ®æ“ä½œï¼ˆå¦‚ modify_valueã€append_afterã€renameï¼‰ã€‚

    å‚æ•°:
        key (str): å…ƒæ•°æ®é”®
        value (str): å…ƒæ•°æ®å€¼
        actions (list): è¦åº”ç”¨çš„æ“ä½œåˆ—è¡¨

    è¿”å›:
        list: è½¬æ¢ä»»åŠ¡åˆ—è¡¨
    """
    tasks = []
    current_key, current_value = key, value
    modified = False

    sorted_actions = sorted(
        [a for a in actions if a.get("type") not in ["retain", "delete"]],
        key=lambda x: {"modify_value": 0, "append_after": 1, "rename": 2}.get(x.get("type"), 999)
    )

    for action in sorted_actions:
        action_type = action.get("type")
        if action_type == "modify_value":
            value_mapping = action.get("value_mapping", {})
            regex_mapping = action.get("regex_mapping", [])
            if current_value in value_mapping:
                current_value = value_mapping[current_value]
                modified = True
            else:
                for regex, replacement in regex_mapping:
                    match = re.search(regex, current_value)
                    if match:
                        # Check if the regex contains capturing groups
                        if match.groups():
                            # Use the regex replacement with capture groups
                            current_value = re.sub(regex, replacement, current_value)
                        else:
                            # No capture groups, use replacement as default
                            current_value = replacement
                        modified = True
                        break
        elif action_type == "append_after":
            current_value += action.get("content", "")
            modified = True
        elif action_type == "rename":
            current_key = action.get("new_name", key)
            modified = True

    if modified:
        tasks.append({
            "type": TaskType.TRANSFORM_METADATA.value,
            "key": key,
            "original_line": f"{key}: {value}",
            "new_line": f"{current_key}: {current_value}",
            "action": {"type": "replace"}
        })
    return tasks

def generate_metadata_tasks(md_file, metadata_rules, config):
    """
    è§£æ Markdown æ–‡ä»¶ä¸­çš„å…ƒæ•°æ®å¹¶ç”Ÿæˆè½¬æ¢ä»»åŠ¡ã€‚

    å‚æ•°:
        md_file (str æˆ– Path): Markdown æ–‡ä»¶çš„è·¯å¾„
        metadata_rules (dict): å¤„ç†å…ƒæ•°æ®çš„è§„åˆ™
        config (dict): é…ç½®å­—å…¸

    è¿”å›:
        list: å…ƒæ•°æ®è½¬æ¢ä»»åŠ¡åˆ—è¡¨
    """
    tasks = []
    metadata_lines = read_metadata_lines(md_file, metadata_rules, config)  # Pass metadata_rules here
    for line in metadata_lines:
        tasks.extend(process_metadata_line(line, metadata_rules, config))
    return tasks

#############################################################
# DIRECTORY SCANNING AND TASK PLANNING
#############################################################

# Functions in this section handle scanning directories and planning tasks.
# These include `initialize_scan_stats`, `scan_markdown_file`,
# `scan_attachments`, `generate_rename_markdown_task`, and `scan_directory`.

def initialize_scan_stats():
    """
    åˆå§‹åŒ–æ‰«æè¿‡ç¨‹çš„ç»Ÿè®¡ä¿¡æ¯å’Œå˜é‡ã€‚

    è¿”å›:
        tuple: åŒ…å«ç»Ÿè®¡ä¿¡æ¯å­—å…¸ã€æœªæ˜ å°„å…ƒæ•°æ®å­—å…¸å’Œå·²ä½¿ç”¨åç§°é›†åˆçš„å…ƒç»„
    """
    return {
        "markdown_files": 0,
        "attachments": 0,
        "conflicts": 0,
        "metadata_tasks": 0,
        "unmapped_metadata": 0
    }, {}, set()


def scan_markdown_file(file, root, directory, resource_dir, metadata_rules, stats, tasks, config):
    """
    å¤„ç†å•ä¸ª Markdown æ–‡ä»¶ã€‚

    å‚æ•°:
        file (str): Markdown æ–‡ä»¶çš„åç§°
        root (str): æ–‡ä»¶çš„æ ¹ç›®å½•
        directory (str): æ­£åœ¨æ‰«æçš„åŸºç›®å½•
        resource_dir (Path): èµ„æºç›®å½•çš„è·¯å¾„
        metadata_rules (dict): å¤„ç†å…ƒæ•°æ®çš„è§„åˆ™
        stats (dict): ç”¨äºè·Ÿè¸ªç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        tasks (list): ç”¨äºæ”¶é›†ç”Ÿæˆä»»åŠ¡çš„åˆ—è¡¨
        config (dict): é…ç½®å­—å…¸
    """
    trace_debug("------------------------------------------------------------", config)
    trace_debug(f"ğŸ” Processing Markdown file: {file}", config)

    original_path = Path(root) / file
    stats["markdown_files"] += 1

    # Step 1: Add metadata mapping tasks
    trace_debug("ğŸ› ï¸ 1.Generating metadata transformation tasks...", config)
    metadata_tasks = generate_metadata_tasks(original_path, metadata_rules, config)
    tasks.extend(metadata_tasks)
    stats["metadata_tasks"] += len(metadata_tasks)

    # Step 2: Process attachments
    trace_debug("ğŸ“¦ 2.Processing attachments...", config)
    path_mapping = scan_attachments(original_path, directory, resource_dir, stats, tasks, config)

    # Step 3: Update references in Markdown file
    trace_debug("ğŸ”— 3.Updating references in Markdown file...", config)
    if path_mapping:  # Only add the task if path_mapping is not empty
        update_task = {"type": TaskType.UPDATE_ATTACH_REF.value, "file": original_path, "path_mapping": path_mapping}
        trace_debug(f"â• Added update references task: {update_task}", config)
        tasks.append(update_task)

    # Step 4: Rename Markdown file
    trace_debug("âœï¸ 4.Renaming Markdown file...", config)
    rename_task = generate_rename_markdown_task(original_path, directory, tasks, config)
    if rename_task:
        trace_debug(f"â• Added rename task: {rename_task}", config)

    trace_debug(f"âœ… 5.Finished processing Markdown file: {file}", config)

def scan_attachments(original_path, directory, resource_dir, stats, tasks, config):
    """
    å¤„ç†ç»™å®š Markdown æ–‡ä»¶çš„é™„ä»¶ã€‚

    å‚æ•°:
        original_path (Path): Markdown æ–‡ä»¶çš„è·¯å¾„
        directory (str): æ­£åœ¨æ‰«æçš„åŸºç›®å½•
        resource_dir (Path): èµ„æºç›®å½•çš„è·¯å¾„
        stats (dict): ç”¨äºè·Ÿè¸ªç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        tasks (list): ç”¨äºæ”¶é›†ç”Ÿæˆä»»åŠ¡çš„åˆ—è¡¨
        config (dict): é…ç½®å­—å…¸

    è¿”å›:
        dict: æ—§é™„ä»¶è·¯å¾„åˆ°æ–°è·¯å¾„çš„æ˜ å°„
    """
    # Extract UID from the Markdown filename
    uid_match = re.search(r" (\w{32})\.md$", str(original_path))
    attachment_dir = None
    
    if uid_match:
        uid = uid_match.group(1)
        trace_debug(f"ğŸ“Œ Found UID in Markdown filename: {uid}", config)
        
        # Look for an attachment directory with matching UID in its name
        parent_dir = original_path.parent
        potential_dirs = [d for d in parent_dir.iterdir() if d.is_dir()]
        
        for pot_dir in potential_dirs:
            if uid in pot_dir.name:
                attachment_dir = pot_dir
                trace_debug(f"ğŸ“‚ Found matching attachment directory: {attachment_dir}", config)
                break
    
    # If no attachment directory with matching UID is found, assume no attachments
    if not attachment_dir:
        trace_debug(f"â„¹ï¸ No attachment directory found for {original_path.name}, skipping attachment processing", config)
        return {}  # Return empty mapping as there are no attachments

    path_mapping = {}
    if attachment_dir.exists():
        attachment_count = sum(1 for _ in attachment_dir.iterdir())
        trace_debug(f"ğŸ“„ Found {attachment_count} attachments in {attachment_dir}", config)
        
        for i, attachment in enumerate(attachment_dir.iterdir(), start=1):
            stats["attachments"] += 1
            if attachment_count == 1:
                # Single attachment: Use Markdown file name
                new_attachment_name = f"{original_path.stem}{attachment.suffix}"
            else:
                # Multiple attachments: Append sequence number
                new_attachment_name = f"{original_path.stem}_{i}{attachment.suffix}"
            new_attachment_path = resource_dir / new_attachment_name
            old_path = quote(str(attachment.relative_to(directory)).replace("\\", "/"))
            new_path = str(new_attachment_path.relative_to(directory)).replace("\\", "/")
            path_mapping[old_path] = new_path
            move_task = {"type": TaskType.MOVE_ATTACHMENT.value, "src": attachment, "dest": new_attachment_path}
            trace_debug(f"â• Added move attachment task: {move_task}", config)
            tasks.append(move_task)
    
    return path_mapping

def generate_rename_markdown_task(original_path, directory, tasks, config):
    """
    é€šè¿‡ç§»é™¤ UID å¹¶è§£å†³å†²çªæ¥é‡å‘½å Markdown æ–‡ä»¶ã€‚

    å‚æ•°:
        original_path (Path): Markdown æ–‡ä»¶çš„è·¯å¾„
        directory (str): æ­£åœ¨æ‰«æçš„åŸºç›®å½•
        tasks (list): ç”¨äºæ”¶é›†ç”Ÿæˆä»»åŠ¡çš„åˆ—è¡¨
        config (dict): é…ç½®å­—å…¸

    è¿”å›:
        dict: æ·»åŠ åˆ°ä»»åŠ¡åˆ—è¡¨ä¸­çš„é‡å‘½åä»»åŠ¡
    """
    base_name = re.sub(r" \w{32}$", "", original_path.stem)  # Remove UID
    new_name = base_name
    counter = 1
    while new_name in [task.get("dest", "").stem for task in tasks if task["type"] == TaskType.RENAME_MD.value]:
        new_name = f"{base_name}_{counter}"
        counter += 1
    new_md_path = Path(directory) / f"{new_name}.md"
    rename_task = {"type": TaskType.RENAME_MD.value, "src": original_path, "dest": new_md_path}
    tasks.append(rename_task)
    return rename_task


def scan_directory(directory, attachment_output_path, metadata_rules, config):
    """
    æ‰«æç›®å½•ä¸­çš„ Markdown æ–‡ä»¶å¹¶ç”Ÿæˆå¤„ç†ä»»åŠ¡ã€‚

    å‚æ•°:
        directory (str): è¦æ‰«æçš„ç›®å½•è·¯å¾„
        attachment_output_path (str): èµ„æºç›®å½•çš„åç§°
        metadata_rules (dict): å¤„ç†å…ƒæ•°æ®çš„è§„åˆ™
        config (dict): é…ç½®å­—å…¸

    è¿”å›:
        tuple: åŒ…å«ä»»åŠ¡åˆ—è¡¨ã€ç»Ÿè®¡ä¿¡æ¯å­—å…¸å’Œæœªæ˜ å°„å…ƒæ•°æ®å­—å…¸çš„å…ƒç»„
    """
    trace_debug("ğŸš€ Starting directory scan...", config)
    print("Scanning directory for Markdown files...")
    tasks = []
    stats, unmapped_metadata, used_names = initialize_scan_stats()
    resource_dir = Path(directory) / attachment_output_path
    resource_dir.mkdir(exist_ok=True)

    trace_debug(f"ğŸ“‚ Resource directory created at: {resource_dir}", config)

    # è·å–æ‰€æœ‰ Markdown æ–‡ä»¶æ•°é‡ç”¨äºè¿›åº¦æ¡
    if not config.get("debug", False):
        md_files = []
        for root, _, files in os.walk(directory):
            for file in files:
                if file.endswith(".md"):
                    md_files.append(os.path.join(root, file))
        total_files = len(md_files)
        current_file = 0
        
        # é‡ç½®è¿›åº¦æ¡è®¡æ—¶å™¨
        if hasattr(display_progress_bar, "start_time"):
            delattr(display_progress_bar, "start_time")

    # Scan for Markdown files
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(".md"):
                if not config.get("debug", False):
                    current_file += 1
                    display_progress_bar(current_file, total_files, f"æ‰«æ: {file}")
                
                trace_debug(f"ğŸ“„ Found Markdown file: {file}", config)
                scan_markdown_file(file, root, directory, resource_dir, metadata_rules, stats, tasks, config)

    trace_debug("âœ… Directory scan completed.", config)
    print_progress(1, 3)  # Scanning is step 1 of 3
    return tasks, stats, unmapped_metadata

#############################################################
# TASK EXECUTION
#############################################################

# Functions in this section handle task execution.
# These include `execute_task` and `execute_tasks`.

def execute_task(task, config, path_mapping):
    """
    æ ¹æ®ä»»åŠ¡ç±»å‹æ‰§è¡Œå•ä¸ªä»»åŠ¡ã€‚

    å‚æ•°:
        task (dict): è¦æ‰§è¡Œçš„ä»»åŠ¡
        config (dict): é…ç½®å­—å…¸
        path_mapping (dict): æ—§è·¯å¾„åˆ°æ–°è·¯å¾„çš„æ˜ å°„
    """
    try:
        if task["type"] == TaskType.RENAME_MD.value:
            trace_debug(f"âœï¸ é‡å‘½åæ–‡ä»¶: {task['src']} -> {task['dest']}", config)
            Path(task["src"]).rename(task["dest"])
            path_mapping[str(task["src"])] = str(task["dest"])
        elif task["type"] == TaskType.MOVE_ATTACHMENT.value:
            trace_debug(f"ğŸ“¦ ç§»åŠ¨é™„ä»¶: {task['src']} -> {task['dest']}", config)
            Path(task["src"]).rename(task["dest"])
        elif task["type"] == TaskType.UPDATE_ATTACH_REF.value:
            trace_debug(f"ğŸ”— æ›´æ–°æ–‡ä»¶ä¸­çš„å¼•ç”¨: {task['file']}", config)
            update_references_in_markdown(task["file"], task["path_mapping"], config.get("metadata_rules", {}), config)
        elif task["type"] == TaskType.TRANSFORM_METADATA.value:
            trace_debug(f"ğŸ› ï¸ è½¬æ¢æ–‡ä»¶ä¸­çš„å…ƒæ•°æ®: {task['file']}", config)
            map_metadata(task["file"], config.get("metadata_rules", {}), config)
        elif task["type"] == TaskType.CLEANUP.value:
            trace_debug(f"ğŸ—‘ï¸ æ¸…ç†æ–‡ä»¶: {task['md_file']}", config)
            if task["md_file"].exists():
                task["md_file"].unlink()
            if task["attachment_dir"].exists():
                shutil.rmtree(task["attachment_dir"])
    except Exception as e:
        trace_debug(f"âŒ æ‰§è¡Œä»»åŠ¡ {task['type']} æ—¶å‡ºé”™: {e}", config)
        if config.get("stop_on_error", False):
            raise

def execute_tasks(tasks, config):
    """
    æŒ‰ç”Ÿæˆé¡ºåºæ‰§è¡Œä»»åŠ¡åˆ—è¡¨ã€‚

    å‚æ•°:
        tasks (list): è¦æ‰§è¡Œçš„ä»»åŠ¡åˆ—è¡¨
        config (dict): é…ç½®å­—å…¸
    """
    trace_debug("ğŸš€ Starting task execution...", config)
    path_mapping = {}
    total_tasks = len(tasks)
    
    # é‡ç½®è¿›åº¦æ¡è®¡æ—¶å™¨
    if hasattr(display_progress_bar, "start_time"):
        delattr(display_progress_bar, "start_time")
    
    for i, task in enumerate(tasks, start=1):
        task_type = task['type']
        task_desc = ""
        
        if task_type == TaskType.RENAME_MD.value:
            task_desc = f"é‡å‘½å: {Path(task['src']).name}"
        elif task_type == TaskType.MOVE_ATTACHMENT.value:
            task_desc = f"ç§»åŠ¨é™„ä»¶: {Path(task['src']).name}"
        elif task_type == TaskType.UPDATE_ATTACH_REF.value:
            task_desc = f"æ›´æ–°å¼•ç”¨: {Path(task['file']).name}"
        elif task_type == TaskType.TRANSFORM_METADATA.value:
            task_desc = f"è½¬æ¢å…ƒæ•°æ®"
        
        if not config.get("debug", False):
            display_progress_bar(i, total_tasks, task_desc)
        
        trace_debug(f"âš™ï¸ Executing task {i}/{total_tasks}: {task['type']}", config)
        execute_task(task, config, path_mapping)
    
    trace_debug("âœ… Task execution completed.", config)

#############################################################
# METADATA TRANSFORMATION
#############################################################

# Functions in this section handle metadata transformation.
# These include `apply_action`, `transform_metadata`, `update_references_in_markdown`, and `map_metadata`.

def apply_action(key, value, action, config):
    """
    å¯¹é”®å€¼å¯¹åº”ç”¨å…ƒæ•°æ®è½¬æ¢æ“ä½œã€‚

    å‚æ•°:
        key (str): å…ƒæ•°æ®é”®
        value (str): å…ƒæ•°æ®å€¼
        action (dict): è¦åº”ç”¨çš„æ“ä½œ
        config (dict, optional): é…ç½®å­—å…¸

    è¿”å›:
        tuple: (æ–°é”®, æ–°å€¼) æˆ– (None, None)ï¼ˆå¦‚æœå…ƒæ•°æ®åº”è¢«åˆ é™¤ï¼‰
    """
    trace_debug(f"ğŸ”§ Applying action '{action.get('type')}' on key '{key}' with value '{value}'", config)
    action_type = action.get("type")
    if action_type == "delete":
        trace_debug(f"ğŸ—‘ï¸ Deleting metadata key: {key}", config)
        return None, None  # Indicate deletion
    elif action_type == "rename":
        new_name = action.get("new_name", key)
        trace_debug(f"âœï¸ Renaming key '{key}' to '{new_name}'", config)
        return new_name, value
    elif action_type == "modify_value":
        value_mapping = action.get("value_mapping", {})
        regex_mapping = action.get("regex_mapping", [])
        new_value = value.strip()

        # Apply direct value mapping
        if new_value in value_mapping:
            trace_debug(f"ğŸ”„ Mapping value '{new_value}' to '{value_mapping[new_value]}'", config)
            new_value = value_mapping[new_value]

        # Apply regex-based transformations
        for regex, replacement in regex_mapping:
            if re.search(regex, new_value):
                trace_debug(f"ğŸ” Regex '{regex}' matched. Replacing '{new_value}' with '{replacement}'", config)
                new_value = re.sub(regex, replacement, new_value)
                break

        return key, new_value
    elif action_type == "append_after":
        content = action.get("content", "")
        trace_debug(f"â• Appending '{content}' to value '{value.strip()}'", config)
        return key, f"{value.strip()}{content}"
    else:
        trace_debug(f"âš ï¸ Unsupported action type '{action_type}' for key '{key}'", config)
        return key, value

def transform_metadata(lines, metadata_rules, config):
    """
    æ ¹æ®è§„åˆ™è½¬æ¢å…ƒæ•°æ®è¡Œã€‚

    å‚æ•°:
        lines (list): å¯èƒ½åŒ…å«å…ƒæ•°æ®çš„è¡Œåˆ—è¡¨
        metadata_rules (dict): å¤„ç†å…ƒæ•°æ®çš„è§„åˆ™
        config (dict, optional): é…ç½®å­—å…¸

    è¿”å›:
        list: è½¬æ¢åçš„è¡Œ
    """
    trace_debug("Starting metadata transformation...", config)
    transformed_lines = []
    for line in lines:
        key, sep, value = line.partition(": ")
        if not sep:  # Skip lines that are not metadata
            transformed_lines.append(line)
            continue

        trace_debug(f"ğŸ” Processing metadata: {key}: {value.strip()}", config)
        rule = metadata_rules.get(key)
        if not rule:  # No rule, retain the line
            trace_debug(f"âš ï¸ No rule found for key: {key}", config)
            transformed_lines.append(line)
            continue

        actions = rule.get("actions", [])
        trace_debug(f"ğŸ”§ Found {len(actions)} actions for key: {key}", config)

        current_key, current_value = key, value.strip()
        for i, action in enumerate(actions):
            trace_debug(f"ğŸ”§ Applying action {i + 1}: {action.get('type')}", config)
            current_key, current_value = apply_action(current_key, current_value, action, config)
            if current_key is None:  # If deleted, stop processing further actions
                trace_debug(f"ğŸ—‘ï¸ Key deleted: {key}", config)
                break

        if current_key is not None:  # If not deleted, add the transformed metadata
            transformed_line = f"{current_key}: {current_value}"
            trace_debug(f"âœ… Transformed: {transformed_line}", config)
            transformed_lines.append(transformed_line)

    return transformed_lines

def update_references_in_markdown(file, path_mapping, metadata_rules, config):
    """
    æ›´æ–° Markdown æ–‡ä»¶ä¸­çš„å¼•ç”¨å¹¶è½¬æ¢å…ƒæ•°æ®ã€‚

    å‚æ•°:
        file (stræˆ–Path): Markdown æ–‡ä»¶çš„è·¯å¾„ã€‚
        path_mapping (dict): æ—§è·¯å¾„åˆ°æ–°è·¯å¾„çš„æ˜ å°„ã€‚
        metadata_rules (dict): å¤„ç†å…ƒæ•°æ®çš„è§„åˆ™ã€‚
        config (dict, optional): ç”¨äºæ—¥å¿—è®°å½•çš„é…ç½®ã€‚
    """
    try:
        with open(file, "r") as f:
            content = f.readlines()

        trace_debug(f"Updating references and metadata in: {file}", config)
        trace_debug(f"Path mapping: {path_mapping}", config)

        # Process metadata transformation
        metadata_end_index = 0
        for i, line in enumerate(content):
            if line.strip() == "":  # Assume metadata ends at the first blank line
                metadata_end_index = i
                break

        metadata_lines = content[:metadata_end_index]
        transformed_metadata = transform_metadata(metadata_lines, metadata_rules, config)
        content = transformed_metadata + content[metadata_end_index:]

        # Update references
        updated_content = []
        for i, line in enumerate(content, start=1):
            original_line = line
            for old_path, new_path in path_mapping.items():
                if old_path in line:
                    encoded_new_path = quote(new_path)
                    line = line.replace(old_path, encoded_new_path)
                    trace_debug(f"Line {i}:\n   Original: {original_line.strip()}\n   Updated:  {line.strip()}", config)
                    log_debug(f"Updated reference in {file} line {i}: {old_path} -> {encoded_new_path}", config)
            updated_content.append(line)

        with open(file, "w") as f:
            f.writelines(updated_content)

        trace_debug(f"æ›´æ–°æ–‡ä»¶ {file} ä¸­çš„å¼•ç”¨å®Œæˆ", config)
    except Exception as e:
        trace_debug(f"âŒ Error updating references in {file}: {e}", config)
        log_debug(f"ERROR updating references in {file}: {e}", config)

def map_metadata(file, metadata_rules, config):
    """
    æ˜ å°„å¹¶è½¬æ¢ Markdown æ–‡ä»¶ä¸­çš„å…ƒæ•°æ®ã€‚

    å‚æ•°:
        file (str æˆ– Path): Markdown æ–‡ä»¶çš„è·¯å¾„
        metadata_rules (dict): å¤„ç†å…ƒæ•°æ®çš„è§„åˆ™
        config (dict, optional): é…ç½®å­—å…¸
    """
    try:
        trace_debug(f"ğŸ“‹ Metadata rules: {metadata_rules}", config)
        with open(file, "r") as f:
            content = f.readlines()

        metadata_end_index = 0
        for i, line in enumerate(content):
            if line.strip() == "":  # Assume metadata ends at the first blank line
                metadata_end_index = i
                break

        metadata_lines = content[:metadata_end_index]
        transformed_metadata = transform_metadata(metadata_lines, metadata_rules, config)

        trace_debug(f"Metadata changes for {file}:", config)
        for original, transformed in zip(metadata_lines, transformed_metadata):
            if original.strip() != transformed.strip():
                trace_debug(f"   Original: {original.strip()}\n   Transformed: {transformed.strip()}", config)
                log_debug(f"Transformed metadata in {file}: {original.strip()} -> {transformed.strip()}", config)

        content = transformed_metadata + content[metadata_end_index:]

        with open(file, "w") as f:
            f.writelines(content)

        trace_debug(f"æ˜ å°„æ–‡ä»¶ {file} çš„å…ƒæ•°æ®å®Œæˆ", config)
    except Exception as e:
        trace_debug(f"âŒ Error mapping metadata in {file}: {e}", config)
        log_debug(f"ERROR mapping metadata in {file}: {e}", config)

#############################################################
# MAIN FUNCTION
#############################################################

# Functions in this section handle the main script execution.
# These include `print_introduction`, `parse_arguments`, `load_and_configure`,
# `print_statistics`, `confirm_execution`, `print_final_statistics`, and `main`.

def print_introduction():
    """
    æ‰“å°è„šæœ¬çš„ç®€è¦ä»‹ç»ã€‚
    """
    intro = """
ğŸ’¼ Obsidian Import Tool ğŸ“š
--------------------------
A tool to process Notion exports for use in Obsidian.

This tool helps you:
- Clean up filenames by removing UIDs
- Consolidate all attachments into a single resource directory
- Update markdown references to point to the new paths
- Transform metadata based on custom rules

Usage examples:
  python3 obsidian_import.py /path/to/notion/export  # Process an export directory
  python3 obsidian_import.py --help                  # Show all available options

Get started by running with a directory path.
"""
    print(intro)

def parse_arguments():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°ã€‚
    """
    parser = argparse.ArgumentParser(
        description="Transform Notion exports for use in Obsidian - consolidates resources and cleans up metadata.",
        epilog="For detailed documentation, refer to the script comments."
    )
    parser.add_argument("directory", help="The directory to process", nargs="?")
    parser.add_argument("--config", help="Path to the configuration file", default="obsidian_import.yaml")
    parser.add_argument("--log", help="Path to the log file (enables logging if specified)")
    parser.add_argument("--debug", action="store_true", help="Enable debug output (overrides config)")
    parser.add_argument("--reset-log", action="store_true", help="Clear the log file before starting")
    return parser

def reset_log_file(config):
    """
    å¦‚æœé…ç½®ä¸­å¯ç”¨äº†é‡ç½®æ—¥å¿—ï¼Œåˆ™æ¸…ç©ºæ—¥å¿—æ–‡ä»¶ã€‚

    å‚æ•°:
        config (dict): åŒ…å«æ—¥å¿—è®¾ç½®çš„é…ç½®å­—å…¸
    """
    if config.get("reset_log", False) and config.get("log_debug", False):
        log_file = Path(config.get("log_file", "obsidian_import.log"))
        with open(log_file, "w") as f:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            f.write(f"[{timestamp}] æ—¥å¿—: Log file reset by user request\n")
        trace_debug(f"Log file reset at {log_file}", config)

def load_and_configure(args):
    """
    ä»æ–‡ä»¶åŠ è½½é…ç½®å¹¶åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–ã€‚

    å‚æ•°:
        args (argparse.Namespace): è§£æçš„å‘½ä»¤è¡Œå‚æ•°

    è¿”å›:
        dict: åº”ç”¨è¦†ç›–åçš„é…ç½®å­—å…¸
    """
    config = load_config(args.config)

    # Apply command-line overrides
    if args.log:
        config["log_debug"] = True
        config["log_file"] = args.log
    config["debug"] = args.debug  # Use --debug argument to control debug output
    config["reset_log"] = args.reset_log  # Store the reset-log flag

    return config

def print_statistics(stats, unmapped_metadata, tasks):
    """
    æ‰“å°æ€»ç»“ä»»åŠ¡çš„ç»Ÿè®¡ä¿¡æ¯ã€‚

    å‚æ•°:
        stats (dict): åŒ…å«æ‰«æç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        unmapped_metadata (dict): æœªæ˜ å°„å…ƒæ•°æ®å€¼çš„å­—å…¸
        tasks (list): æ‰«ææœŸé—´ç”Ÿæˆçš„ä»»åŠ¡åˆ—è¡¨
    """
    # å¦‚æœæœ‰è¿›åº¦æ¡ï¼Œç¡®ä¿åœ¨æ‰“å°ç»Ÿè®¡ä¿¡æ¯å‰å®Œæˆè¿›åº¦æ¡
    if hasattr(display_progress_bar, "last_line"):
        sys.stdout.write("\n")
        sys.stdout.flush()

    print("\nğŸ“Š æ‰«æç»Ÿè®¡ä¿¡æ¯:")
    print("-------------------")
    print(f"å¤„ç†çš„ Markdown æ–‡ä»¶æ•°é‡: {stats.get('markdown_files', 0)}")
    print(f"å¤„ç†çš„é™„ä»¶æ•°é‡: {stats.get('attachments', 0)}")
    print(f"å…ƒæ•°æ®è½¬æ¢ä»»åŠ¡æ•°é‡: {stats.get('metadata_tasks', 0)}")
    print(f"æœªæ˜ å°„çš„å…ƒæ•°æ®æ¡ç›®: {stats.get('unmapped_metadata', 0)}")
    print(f"ç”Ÿæˆçš„æ€»ä»»åŠ¡æ•°é‡: {len(tasks)}")

    if unmapped_metadata:
        print("\nâš ï¸ æœªæ˜ å°„çš„å…ƒæ•°æ®:")
        for key, values in unmapped_metadata.items():
            print(f"  - {key}: {', '.join(values)}")

    print("\nğŸ“‹ ä»»åŠ¡æ‘˜è¦:")
    task_counts = {}
    for task in tasks:
        task_type = task['type']
        if task_type not in task_counts:
            task_counts[task_type] = 0
        task_counts[task_type] += 1
    
    for task_type, count in task_counts.items():
        print(f"  â€¢ {task_type}: {count} ä¸ªä»»åŠ¡")

def confirm_execution():
    """
    åœ¨æ‰§è¡Œä»»åŠ¡åˆ—è¡¨ä¹‹å‰æç¤ºç”¨æˆ·ç¡®è®¤ã€‚

    è¿”å›:
        bool: å¦‚æœç”¨æˆ·ç¡®è®¤åˆ™ä¸º Trueï¼Œå¦åˆ™ä¸º False
    """
    response = input("Do you want to proceed with the tasks? (yes/no): ").strip().lower()
    return response in ["yes", "y"]

def print_final_statistics(tasks, execution_time, config):
    """
    åœ¨æ‰§è¡Œä»»åŠ¡åæ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯ã€‚

    å‚æ•°:
        tasks (list): å·²æ‰§è¡Œçš„ä»»åŠ¡åˆ—è¡¨
        execution_time (float): æ€»æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
        config (dict): é…ç½®å­—å…¸
    """
    print("\nâœ… Task Execution Complete")
    print("--------------------------")
    print(f"Total tasks executed: {len(tasks)}")
    print(f"Execution time: {execution_time:.2f} seconds")

    if config.get("log_debug", False):
        log_debug(f"Task execution completed in {execution_time:.2f} seconds", config)

def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºåè°ƒ Obsidian å¯¼å…¥è¿‡ç¨‹ã€‚

    æ­¥éª¤:
    1. è§£æå‘½ä»¤è¡Œå‚æ•°
    2. åŠ è½½é…ç½®å¹¶åº”ç”¨è¦†ç›–
    3. æ‰«æç›®å½•å¹¶ç”Ÿæˆä»»åŠ¡
    4. æ‰“å°ç»Ÿè®¡ä¿¡æ¯å¹¶æç¤ºç¡®è®¤
    5. å¦‚æœç¡®è®¤ï¼Œæ‰§è¡Œä»»åŠ¡
    6. æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯å’Œæ‰§è¡Œæ—¶é—´
    """
    parser = parse_arguments()
    if len(sys.argv) == 1:
        print_introduction()
        parser.print_help()
        return

    args = parser.parse_args()

    if not args.directory:
        parser.error("the following arguments are required: directory")

    config = load_and_configure(args)
    
    # Reset the log file if requested
    reset_log_file(config)
    
    trace_debug("ğŸš€ Starting Obsidian Import Tool...", config)

    directory = args.directory
    attachment_output_path = config.get("attachment_output_path", "Resource")
    metadata_rules = config.get("metadata_rules", {})

    if config.get("log_debug", False):
        log_debug(f"Starting obsidian_import.py on {directory}", config)

    # Step 1: Scan the directory
    tasks, stats, unmapped_metadata = scan_directory(directory, attachment_output_path, metadata_rules, config)

    # Step 2: Display statistics
    print_statistics(stats, unmapped_metadata, tasks)

    # Step 3: Prompt for confirmation
    if not confirm_execution():
        log_debug("Operation canceled by the user.", config)
        print("Operation canceled.")
        return

    # Step 4: Execute tasks
    print("Executing tasks...")
    start_time = time.time()
    execute_tasks(tasks, config)
    end_time = time.time()

    # Step 5: Print final statistics
    print_final_statistics(tasks, end_time - start_time, config)
    trace_debug("âœ… Obsidian Import Tool completed.", None)


if __name__ == "__main__":
    main()

def display_progress_bar(current, total, description="", width=None):
    """
    æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œæ ¼å¼ä¸º: 2/123 [####----] 33% ETA 01:23 å½“å‰å¤„ç†å†…å®¹
    
    å‚æ•°:
        current (int): å½“å‰è¿›åº¦
        total (int): æ€»ä»»åŠ¡æ•°
        description (str): å½“å‰å¤„ç†çš„æè¿°
        width (int, optional): è¿›åº¦æ¡å®½åº¦ï¼Œé»˜è®¤ä¸ºç»ˆç«¯å®½åº¦çš„ä¸€åŠ
    """
    if not width:
        try:
            terminal_width = shutil.get_terminal_size().columns
            width = min(50, terminal_width // 2)  # è¿›åº¦æ¡å®½åº¦ä¸ºç»ˆç«¯å®½åº¦çš„ä¸€åŠï¼Œä½†æœ€å¤§ä¸º50
        except:
            width = 40  # é»˜è®¤å®½åº¦
    
    # è®¡ç®—å®Œæˆç™¾åˆ†æ¯”
    percent = current / total
    
    # è®¡ç®—ETA (é¢„è®¡å‰©ä½™æ—¶é—´)
    if not hasattr(display_progress_bar, "start_time"):
        display_progress_bar.start_time = time.time()
    
    elapsed = time.time() - display_progress_bar.start_time
    if current > 0:
        eta_seconds = (elapsed / current) * (total - current)
        eta_min, eta_sec = divmod(int(eta_seconds), 60)
        eta_str = f"{eta_min:02d}:{eta_sec:02d}"
    else:
        eta_str = "--:--"
    
    # æ„å»ºè¿›åº¦æ¡å­—ç¬¦ä¸²
    completed = int(width * percent)
    progress_bar = "#" * completed + "-" * (width - completed)
    
    # é™åˆ¶æè¿°é•¿åº¦ä»¥é€‚åº”ç»ˆç«¯
    try:
        max_desc_len = max(10, shutil.get_terminal_size().columns - width - 40)  # ä¸ºå…¶ä»–éƒ¨åˆ†ä¿ç•™ç©ºé—´
    except:
        max_desc_len = 50  # é»˜è®¤é•¿åº¦
        
    if len(description) > max_desc_len:
        description = description[:max_desc_len-3] + "..."
    
    # æ„å»ºå®Œæ•´çš„è¿›åº¦æ˜¾ç¤º
    progress_str = f"{current}/{total} [{progress_bar}] {percent*100:.0f}% ETA {eta_str} {description}"
    
    # æ¸…é™¤å½“å‰è¡Œå¹¶æ˜¾ç¤ºè¿›åº¦
    sys.stdout.write("\r" + " " * len(getattr(display_progress_bar, "last_line", "")))
    sys.stdout.write("\r" + progress_str)
    sys.stdout.flush()
    
    # ä¿å­˜æœ€åæ˜¾ç¤ºçš„è¡Œï¼Œä»¥ä¾¿ä¸‹æ¬¡æ¸…é™¤
    display_progress_bar.last_line = progress_str
    
    # å¦‚æœå®Œæˆï¼Œæ·»åŠ æ¢è¡Œ
    if current == total:
        sys.stdout.write("\n")
        sys.stdout.flush()
        if hasattr(display_progress_bar, "start_time"):
            delattr(display_progress_bar, "start_time")
